{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Project\n",
    "\n",
    "import, data load and processing, initialize the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n # MinMaxScaler gives better accuracy, using StandardScaler for grading",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into features and target\n",
    "concrete_data_columns = concrete_data.columns\n",
    "features = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the model as per instruction\n",
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_shape=(8,)))\n",
    "    #1 hidden layer with 10 nodes as per instruction\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's do it manually to see if everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 1527.8364\n",
      "Epoch 2/50\n",
      " - 0s - loss: 811.4881\n",
      "Epoch 3/50\n",
      " - 0s - loss: 439.7747\n",
      "Epoch 4/50\n",
      " - 0s - loss: 281.3024\n",
      "Epoch 5/50\n",
      " - 0s - loss: 209.9583\n",
      "Epoch 6/50\n",
      " - 0s - loss: 179.4431\n",
      "Epoch 7/50\n",
      " - 0s - loss: 147.8480\n",
      "Epoch 8/50\n",
      " - 0s - loss: 135.9786\n",
      "Epoch 9/50\n",
      " - 0s - loss: 131.8748\n",
      "Epoch 10/50\n",
      " - 0s - loss: 119.0273\n",
      "Epoch 11/50\n",
      " - 0s - loss: 125.4540\n",
      "Epoch 12/50\n",
      " - 0s - loss: 109.3252\n",
      "Epoch 13/50\n",
      " - 0s - loss: 112.3001\n",
      "Epoch 14/50\n",
      " - 0s - loss: 108.2260\n",
      "Epoch 15/50\n",
      " - 0s - loss: 105.3052\n",
      "Epoch 16/50\n",
      " - 0s - loss: 103.9475\n",
      "Epoch 17/50\n",
      " - 0s - loss: 99.8988\n",
      "Epoch 18/50\n",
      " - 0s - loss: 101.2911\n",
      "Epoch 19/50\n",
      " - 0s - loss: 99.1703\n",
      "Epoch 20/50\n",
      " - 0s - loss: 98.2293\n",
      "Epoch 21/50\n",
      " - 0s - loss: 98.3051\n",
      "Epoch 22/50\n",
      " - 0s - loss: 99.6345\n",
      "Epoch 23/50\n",
      " - 0s - loss: 97.4081\n",
      "Epoch 24/50\n",
      " - 0s - loss: 95.8234\n",
      "Epoch 25/50\n",
      " - 0s - loss: 91.8823\n",
      "Epoch 26/50\n",
      " - 0s - loss: 94.9484\n",
      "Epoch 27/50\n",
      " - 0s - loss: 92.1276\n",
      "Epoch 28/50\n",
      " - 0s - loss: 97.2940\n",
      "Epoch 29/50\n",
      " - 0s - loss: 96.3826\n",
      "Epoch 30/50\n",
      " - 0s - loss: 94.3892\n",
      "Epoch 31/50\n",
      " - 0s - loss: 93.7090\n",
      "Epoch 32/50\n",
      " - 0s - loss: 91.5540\n",
      "Epoch 33/50\n",
      " - 0s - loss: 86.0635\n",
      "Epoch 34/50\n",
      " - 0s - loss: 88.7694\n",
      "Epoch 35/50\n",
      " - 0s - loss: 82.4127\n",
      "Epoch 36/50\n",
      " - 0s - loss: 85.7220\n",
      "Epoch 37/50\n",
      " - 0s - loss: 79.2594\n",
      "Epoch 38/50\n",
      " - 0s - loss: 80.3250\n",
      "Epoch 39/50\n",
      " - 0s - loss: 90.3223\n",
      "Epoch 40/50\n",
      " - 0s - loss: 79.7617\n",
      "Epoch 41/50\n",
      " - 0s - loss: 73.6655\n",
      "Epoch 42/50\n",
      " - 0s - loss: 70.0240\n",
      "Epoch 43/50\n",
      " - 0s - loss: 73.4476\n",
      "Epoch 44/50\n",
      " - 0s - loss: 66.6153\n",
      "Epoch 45/50\n",
      " - 0s - loss: 67.0655\n",
      "Epoch 46/50\n",
      " - 0s - loss: 66.4784\n",
      "Epoch 47/50\n",
      " - 0s - loss: 62.6659\n",
      "Epoch 48/50\n",
      " - 0s - loss: 61.5397\n",
      "Epoch 49/50\n",
      " - 0s - loss: 64.8793\n",
      "Epoch 50/50\n",
      " - 0s - loss: 65.9608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e5cae72b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 96us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.09193545097672"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a split & train function on non-normalized data, return the mean square error from the test data\n",
    "model = regression_model()\n",
    "def split_train_evaluate():\n",
    "    #1 random split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\n",
    "    #fit with 50 epochs\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    #return the mean square error based on the test data\n",
    "    return model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 137us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 52us/step\n",
      "309/309 [==============================] - 0s 30us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 32us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 73us/step\n",
      "309/309 [==============================] - 0s 56us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 29us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 36us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 52us/step\n",
      "309/309 [==============================] - 0s 37us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 47us/step\n",
      "309/309 [==============================] - 0s 29us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 35us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 47us/step\n",
      "309/309 [==============================] - 0s 53us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 36us/step\n",
      "309/309 [==============================] - 0s 37us/step\n",
      "309/309 [==============================] - 0s 33us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 38us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 47us/step\n",
      "309/309 [==============================] - 0s 62us/step\n",
      "309/309 [==============================] - 0s 31us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 23us/step\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "#split, train and evaluate the model 50 times\n",
    "for i in range(50):\n",
    "    errors.append(split_train_evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean square errors is: 38.789983402980575\n",
      "The standard deviation of the mean square errors is: 17.438625884072408\n"
     ]
    }
   ],
   "source": [
    "#report the results\n",
    "print(\"The mean of the mean square errors is:\", np.mean(errors))\n",
    "print(\"The standard deviation of the mean square errors is:\", np.std(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#normalize the data using MinMaxScaler from sklearn preprocessing\n",
    "scaler = StandardScaler()\n",
    "transform = scaler.fit_transform(features)\n",
    "features_normalized = pd.DataFrame(transform,columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a split & train function on normalized data, return the mean square error from the test data\n",
    "model = regression_model()\n",
    "def split_train_evaluate():\n",
    "    #1 random split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\n",
    "    #fit with 50 epochs\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    #return the mean square error based on the test data\n",
    "    return model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 214us/step\n",
      "309/309 [==============================] - 0s 44us/step\n",
      "309/309 [==============================] - 0s 34us/step\n",
      "309/309 [==============================] - 0s 32us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 121us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 33us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 43us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 32us/step\n",
      "309/309 [==============================] - 0s 29us/step\n",
      "309/309 [==============================] - 0s 41us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 39us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 33us/step\n",
      "309/309 [==============================] - 0s 33us/step\n",
      "309/309 [==============================] - 0s 265us/step\n",
      "309/309 [==============================] - 0s 30us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 51us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 29us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 65us/step\n",
      "309/309 [==============================] - 0s 40us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 31us/step\n",
      "309/309 [==============================] - 0s 24us/step\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "#split, train and evaluate the model 50 times\n",
    "for i in range(50):\n",
    "    errors.append(split_train_evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean square errors is: 35.14684363550353\n",
      "The standard deviation of the mean square errors is: 14.554530471530931\n"
     ]
    }
   ],
   "source": [
    "#report the results\n",
    "print(\"The mean of the mean square errors is:\", np.mean(errors))\n",
    "print(\"The standard deviation of the mean square errors is:\", np.std(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#repeat normalization for full run\n",
    "scaler = StandardScaler()\n",
    "transform = scaler.fit_transform(features)\n",
    "features_normalized = pd.DataFrame(transform,columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a split & train function on normalized data and with a 100 epochs, return the mean square error from the test data\n",
    "model = regression_model()\n",
    "def split_train_evaluate():\n",
    "    #1 random split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\n",
    "    #fit with a 100 epochs\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    #return the mean square error based on the test data\n",
    "    return model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 176us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 36us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 40us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 49us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 31us/step\n",
      "309/309 [==============================] - 0s 30us/step\n",
      "309/309 [==============================] - 0s 31us/step\n",
      "309/309 [==============================] - 0s 46us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 42us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 35us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 35us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 31us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 38us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 76us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 38us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 44us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 70us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 36us/step\n",
      "309/309 [==============================] - 0s 24us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 23us/step\n",
      "309/309 [==============================] - 0s 31us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 30us/step\n",
      "309/309 [==============================] - 0s 29us/step\n",
      "309/309 [==============================] - 0s 25us/step\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "#split, train and evaluate the model 50 times\n",
    "for i in range(50):\n",
    "    errors.append(split_train_evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean square errors is: 24.700796201699767\n",
      "The standard deviation of the mean square errors is: 7.011848986829694\n"
     ]
    }
   ],
   "source": [
    "#report the results\n",
    "print(\"The mean of the mean square errors is:\", np.mean(errors))\n",
    "print(\"The standard deviation of the mean square errors is:\", np.std(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#repeat normalization for full run\n",
    "scaler = StandardScaler()\n",
    "transform = scaler.fit_transform(features)\n",
    "features_normalized = pd.DataFrame(transform,columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the model as per instruction, this time with 3 hidden layers\n",
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_shape=(8,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a split & train function on normalized data and with a 50 epochs, return the mean square error from the test data\n",
    "model = regression_model()\n",
    "def split_train_evaluate():\n",
    "    #1 random split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\n",
    "    #fit with 50 epochs\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    #return the mean square error based on the test data\n",
    "    return model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 216us/step\n",
      "309/309 [==============================] - 0s 42us/step\n",
      "309/309 [==============================] - 0s 36us/step\n",
      "309/309 [==============================] - 0s 40us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 65us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 38us/step\n",
      "309/309 [==============================] - 0s 39us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 42us/step\n",
      "309/309 [==============================] - 0s 73us/step\n",
      "309/309 [==============================] - 0s 69us/step\n",
      "309/309 [==============================] - 0s 28us/step\n",
      "309/309 [==============================] - 0s 36us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 35us/step\n",
      "309/309 [==============================] - 0s 52us/step\n",
      "309/309 [==============================] - 0s 30us/step\n",
      "309/309 [==============================] - 0s 52us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 53us/step\n",
      "309/309 [==============================] - 0s 49us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 39us/step\n",
      "309/309 [==============================] - 0s 35us/step\n",
      "309/309 [==============================] - 0s 54us/step\n",
      "309/309 [==============================] - 0s 62us/step\n",
      "309/309 [==============================] - 0s 52us/step\n",
      "309/309 [==============================] - 0s 26us/step\n",
      "309/309 [==============================] - 0s 29us/step\n",
      "309/309 [==============================] - 0s 25us/step\n",
      "309/309 [==============================] - 0s 50us/step\n",
      "309/309 [==============================] - 0s 102us/step\n",
      "309/309 [==============================] - 0s 31us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 38us/step\n",
      "309/309 [==============================] - 0s 27us/step\n",
      "309/309 [==============================] - 0s 33us/step\n",
      "309/309 [==============================] - 0s 178us/step\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "#split, train and evaluate the model 50 times\n",
    "for i in range(50):\n",
    "    errors.append(split_train_evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean square errors is: 25.74129484531563\n",
      "The standard deviation of the mean square errors is: 10.196822186026749\n"
     ]
    }
   ],
   "source": [
    "#report the results\n",
    "print(\"The mean of the mean square errors is:\", np.mean(errors))\n",
    "print(\"The standard deviation of the mean square errors is:\", np.std(errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
